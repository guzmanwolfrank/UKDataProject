{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Accidents\\Accidents_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2015.csv\n",
      "Processing: Accidents\\Accidents_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2016.csv\n",
      "Processing: Accidents\\Accidents_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2017.csv\n",
      "Processing: Accidents\\Accidents_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2018.csv\n",
      "Processing: Casualties\\Casualties_2015.csv\n",
      "Successfully cleaned: Casualties\\Casualties_2015.csv\n",
      "Processing: Casualties\\Casualties_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Casualties\\Casualties_2017.csv\n",
      "Processing: Casualties\\Casualties_2018.csv\n",
      "Successfully cleaned: Casualties\\Casualties_2018.csv\n",
      "Processing: Casualties\\Causalties_2016.csv\n",
      "Successfully cleaned: Casualties\\Causalties_2016.csv\n",
      "Processing: Vehicles\\Vehicles_2015.csv\n",
      "Successfully cleaned: Vehicles\\Vehicles_2015.csv\n",
      "Processing: Vehicles\\Vehicles_2016.csv\n",
      "Successfully cleaned: Vehicles\\Vehicles_2016.csv\n",
      "Processing: Vehicles\\Vehicles_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Vehicles\\Vehicles_2017.csv\n",
      "Processing: Vehicles\\Vehicles_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\2362213477.py:17: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Vehicles\\Vehicles_2018.csv\n",
      "\n",
      "Cleaning Summary:\n",
      "Total files processed: 12\n",
      "Successfully cleaned: 12\n",
      "Failed cleanings: 0\n",
      "\n",
      "Detailed Reports:\n",
      "\n",
      "File: Accidents\\Accidents_2015.csv\n",
      "Original rows: 140056\n",
      "Cleaned rows: 140056\n",
      "Rows removed: 0\n",
      "Missing values filled: 25299\n",
      "\n",
      "File: Accidents\\Accidents_2016.csv\n",
      "Original rows: 136621\n",
      "Cleaned rows: 136621\n",
      "Rows removed: 0\n",
      "Missing values filled: 8353\n",
      "\n",
      "File: Accidents\\Accidents_2017.csv\n",
      "Original rows: 129982\n",
      "Cleaned rows: 129982\n",
      "Rows removed: 0\n",
      "Missing values filled: 56286\n",
      "\n",
      "File: Accidents\\Accidents_2018.csv\n",
      "Original rows: 122635\n",
      "Cleaned rows: 122635\n",
      "Rows removed: 0\n",
      "Missing values filled: 22842\n",
      "\n",
      "File: Casualties\\Casualties_2015.csv\n",
      "Original rows: 186189\n",
      "Cleaned rows: 186189\n",
      "Rows removed: 0\n",
      "Missing values filled: 0\n",
      "\n",
      "File: Casualties\\Casualties_2017.csv\n",
      "Original rows: 170993\n",
      "Cleaned rows: 170993\n",
      "Rows removed: 0\n",
      "Missing values filled: 32768\n",
      "\n",
      "File: Casualties\\Casualties_2018.csv\n",
      "Original rows: 160597\n",
      "Cleaned rows: 160597\n",
      "Rows removed: 0\n",
      "Missing values filled: 0\n",
      "\n",
      "File: Casualties\\Causalties_2016.csv\n",
      "Original rows: 181384\n",
      "Cleaned rows: 181384\n",
      "Rows removed: 0\n",
      "Missing values filled: 0\n",
      "\n",
      "File: Vehicles\\Vehicles_2015.csv\n",
      "Original rows: 257845\n",
      "Cleaned rows: 257845\n",
      "Rows removed: 0\n",
      "Missing values filled: 0\n",
      "\n",
      "File: Vehicles\\Vehicles_2016.csv\n",
      "Original rows: 252500\n",
      "Cleaned rows: 252500\n",
      "Rows removed: 0\n",
      "Missing values filled: 0\n",
      "\n",
      "File: Vehicles\\Vehicles_2017.csv\n",
      "Original rows: 238926\n",
      "Cleaned rows: 238926\n",
      "Rows removed: 0\n",
      "Missing values filled: 65536\n",
      "\n",
      "File: Vehicles\\Vehicles_2018.csv\n",
      "Original rows: 226409\n",
      "Cleaned rows: 226409\n",
      "Rows removed: 0\n",
      "Missing values filled: 32768\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def clean_csv_file(file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Clean a single CSV file and save the cleaned version\n",
    "    \n",
    "    Parameters:\n",
    "    file_path (str): Path to the input CSV file\n",
    "    output_folder (str): Path to save the cleaned CSV file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        original_columns = df.columns.tolist()\n",
    "        \n",
    "        # Store original row count\n",
    "        original_rows = len(df)\n",
    "        \n",
    "        # Basic cleaning operations\n",
    "        \n",
    "        # 1. Remove duplicates\n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        # 2. Strip whitespace from string columns\n",
    "        string_columns = df.select_dtypes(include=['object']).columns\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].str.strip() if df[col].dtype == 'object' else df[col]\n",
    "        \n",
    "        # 3. Standardize text case in string columns\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].str.title() if df[col].dtype == 'object' else df[col]\n",
    "            \n",
    "        # 4. Handle missing values\n",
    "        # Replace empty strings with NaN\n",
    "        df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        \n",
    "        # For numeric columns, fill NaN with median\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_columns:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "            \n",
    "        # For string columns, fill NaN with 'Unknown'\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            \n",
    "        # 5. Remove rows where all values are NaN\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Create cleaning report\n",
    "        cleaning_report = {\n",
    "            'original_rows': original_rows,\n",
    "            'cleaned_rows': len(df),\n",
    "            'rows_removed': original_rows - len(df),\n",
    "            'missing_values_filled': (df == 'Unknown').sum().sum(),\n",
    "            'columns_cleaned': original_columns\n",
    "        }\n",
    "        \n",
    "        # Create output filename while preserving the original folder structure\n",
    "        rel_path = os.path.relpath(file_path, \"Data\")\n",
    "        output_path = os.path.join(output_folder, rel_path)\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        \n",
    "        # Create the necessary subdirectories in the output folder\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Create output filename\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        cleaned_file_path = os.path.join(output_dir, f'{base_name}_cleaned_{timestamp}.csv')\n",
    "        \n",
    "        # Save cleaned file\n",
    "        df.to_csv(cleaned_file_path, index=False)\n",
    "        \n",
    "        return cleaned_file_path, cleaning_report\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None, {'error': str(e)}\n",
    "\n",
    "def find_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Recursively find all CSV files in the given folder and its subfolders\n",
    "    \n",
    "    Parameters:\n",
    "    folder_path (str): Path to the root folder\n",
    "    \n",
    "    Returns:\n",
    "    list: List of paths to CSV files\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.csv'):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "def clean_data_folder(data_folder=\"Data\", output_folder=\"Cleaned_Data\"):\n",
    "    \"\"\"\n",
    "    Clean all CSV files in the Data folder and its subfolders\n",
    "    \n",
    "    Parameters:\n",
    "    data_folder (str): Path to the Data folder containing CSV files\n",
    "    output_folder (str): Path to save cleaned CSV files\n",
    "    \"\"\"\n",
    "    # Check if Data folder exists\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"Error: {data_folder} folder not found!\")\n",
    "        return None\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files\n",
    "    csv_files = find_csv_files(data_folder)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {data_folder} or its subfolders\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize summary report\n",
    "    summary_report = {\n",
    "        'total_files': 0,\n",
    "        'successful_cleanings': 0,\n",
    "        'failed_cleanings': 0,\n",
    "        'cleaning_reports': {}\n",
    "    }\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for file_path in csv_files:\n",
    "        rel_path = os.path.relpath(file_path, data_folder)\n",
    "        print(f\"Processing: {rel_path}\")\n",
    "        \n",
    "        cleaned_path, report = clean_csv_file(file_path, output_folder)\n",
    "        \n",
    "        summary_report['total_files'] += 1\n",
    "        if cleaned_path:\n",
    "            summary_report['successful_cleanings'] += 1\n",
    "            summary_report['cleaning_reports'][rel_path] = report\n",
    "            print(f\"Successfully cleaned: {rel_path}\")\n",
    "        else:\n",
    "            summary_report['failed_cleanings'] += 1\n",
    "            summary_report['cleaning_reports'][rel_path] = report\n",
    "            print(f\"Failed to clean: {rel_path}\")\n",
    "    \n",
    "    return summary_report\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the cleaning process\n",
    "    summary = clean_data_folder()\n",
    "    \n",
    "    # Print summary report if cleaning was performed\n",
    "    if summary:\n",
    "        print(\"\\nCleaning Summary:\")\n",
    "        print(f\"Total files processed: {summary['total_files']}\")\n",
    "        print(f\"Successfully cleaned: {summary['successful_cleanings']}\")\n",
    "        print(f\"Failed cleanings: {summary['failed_cleanings']}\")\n",
    "        \n",
    "        # Print detailed reports for each file\n",
    "        print(\"\\nDetailed Reports:\")\n",
    "        for file_name, report in summary['cleaning_reports'].items():\n",
    "            print(f\"\\nFile: {file_name}\")\n",
    "            if 'error' in report:\n",
    "                print(f\"Error: {report['error']}\")\n",
    "            else:\n",
    "                print(f\"Original rows: {report['original_rows']}\")\n",
    "                print(f\"Cleaned rows: {report['cleaned_rows']}\")\n",
    "                print(f\"Rows removed: {report['rows_removed']}\")\n",
    "                print(f\"Missing values filled: {report['missing_values_filled']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: Accidents\\Accidents_2015.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2015.csv\n",
      "Processing: Accidents\\Accidents_2016.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2016.csv\n",
      "Processing: Accidents\\Accidents_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2017.csv\n",
      "Processing: Accidents\\Accidents_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Accidents\\Accidents_2018.csv\n",
      "Processing: Casualties\\Casualties_2015.csv\n",
      "Successfully cleaned: Casualties\\Casualties_2015.csv\n",
      "Processing: Casualties\\Casualties_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Casualties\\Casualties_2017.csv\n",
      "Processing: Casualties\\Casualties_2018.csv\n",
      "Successfully cleaned: Casualties\\Casualties_2018.csv\n",
      "Processing: Casualties\\Causalties_2016.csv\n",
      "Successfully cleaned: Casualties\\Causalties_2016.csv\n",
      "Processing: Vehicles\\Vehicles_2015.csv\n",
      "Successfully cleaned: Vehicles\\Vehicles_2015.csv\n",
      "Processing: Vehicles\\Vehicles_2016.csv\n",
      "Successfully cleaned: Vehicles\\Vehicles_2016.csv\n",
      "Processing: Vehicles\\Vehicles_2017.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Vehicles\\Vehicles_2017.csv\n",
      "Processing: Vehicles\\Vehicles_2018.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Wolfrank\\AppData\\Local\\Temp\\ipykernel_6436\\4151867325.py:160: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully cleaned: Vehicles\\Vehicles_2018.csv\n",
      "\n",
      "HTML report generated at: Cleaned_Data\\cleaning_report.html\n",
      "\n",
      "Cleaning process completed. Check the HTML report for detailed information.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import sys\n",
    "from jinja2 import Template\n",
    "import webbrowser\n",
    "\n",
    "def generate_html_report(summary_report, output_folder):\n",
    "    \"\"\"\n",
    "    Generate an HTML report from the cleaning summary\n",
    "    \"\"\"\n",
    "    html_template = \"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>CSV Cleaning Report</title>\n",
    "        <style>\n",
    "            body {\n",
    "                font-family: Arial, sans-serif;\n",
    "                margin: 20px;\n",
    "                background-color: #f5f5f5;\n",
    "            }\n",
    "            .container {\n",
    "                max-width: 1200px;\n",
    "                margin: 0 auto;\n",
    "                background-color: white;\n",
    "                padding: 20px;\n",
    "                border-radius: 8px;\n",
    "                box-shadow: 0 0 10px rgba(0,0,0,0.1);\n",
    "            }\n",
    "            h1, h2 {\n",
    "                color: #333;\n",
    "            }\n",
    "            .summary-box {\n",
    "                background-color: #f8f9fa;\n",
    "                border: 1px solid #dee2e6;\n",
    "                border-radius: 4px;\n",
    "                padding: 15px;\n",
    "                margin: 10px 0;\n",
    "            }\n",
    "            table {\n",
    "                width: 100%;\n",
    "                border-collapse: collapse;\n",
    "                margin: 15px 0;\n",
    "            }\n",
    "            th, td {\n",
    "                border: 1px solid #dee2e6;\n",
    "                padding: 8px;\n",
    "                text-align: left;\n",
    "            }\n",
    "            th {\n",
    "                background-color: #f8f9fa;\n",
    "            }\n",
    "            tr:nth-child(even) {\n",
    "                background-color: #f8f9fa;\n",
    "            }\n",
    "            .success {\n",
    "                color: #28a745;\n",
    "            }\n",
    "            .warning {\n",
    "                color: #ffc107;\n",
    "            }\n",
    "            .error {\n",
    "                color: #dc3545;\n",
    "            }\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"container\">\n",
    "            <h1>CSV Cleaning Report</h1>\n",
    "            <div class=\"summary-box\">\n",
    "                <h2>Overall Summary</h2>\n",
    "                <p>Total files processed: {{ summary['total_files'] }}</p>\n",
    "                <p>Successfully cleaned: <span class=\"success\">{{ summary['successful_cleanings'] }}</span></p>\n",
    "                <p>Failed cleanings: <span class=\"error\">{{ summary['failed_cleanings'] }}</span></p>\n",
    "                <p>Total rows processed: {{ summary['total_rows_processed'] }}</p>\n",
    "                <p>Total rows cleaned: {{ summary['total_rows_cleaned'] }}</p>\n",
    "                <p>Total null values handled: {{ summary['total_null_values'] }}</p>\n",
    "                <p>Total errors found: {{ summary['total_errors'] }}</p>\n",
    "            </div>\n",
    "\n",
    "            <h2>Folders Processed</h2>\n",
    "            <ul>\n",
    "            {% for folder in summary['folders_processed'] %}\n",
    "                <li>{{ folder }}</li>\n",
    "            {% endfor %}\n",
    "            </ul>\n",
    "\n",
    "            <h2>Columns Processed</h2>\n",
    "            <ul>\n",
    "            {% for column in summary['unique_columns'] %}\n",
    "                <li>{{ column }}</li>\n",
    "            {% endfor %}\n",
    "            </ul>\n",
    "\n",
    "            <h2>Detailed File Reports</h2>\n",
    "            <table>\n",
    "                <tr>\n",
    "                    <th>File Name</th>\n",
    "                    <th>Original Rows</th>\n",
    "                    <th>Cleaned Rows</th>\n",
    "                    <th>Null Values</th>\n",
    "                    <th>Errors Found</th>\n",
    "                    <th>Status</th>\n",
    "                </tr>\n",
    "                {% for file_name, report in summary['cleaning_reports'].items() %}\n",
    "                <tr>\n",
    "                    <td>{{ file_name }}</td>\n",
    "                    {% if 'error' in report %}\n",
    "                    <td colspan=\"4\">{{ report['error'] }}</td>\n",
    "                    <td class=\"error\">Failed</td>\n",
    "                    {% else %}\n",
    "                    <td>{{ report['original_rows'] }}</td>\n",
    "                    <td>{{ report['cleaned_rows'] }}</td>\n",
    "                    <td>{{ report['null_values'] }}</td>\n",
    "                    <td>{{ report['errors_found'] }}</td>\n",
    "                    <td class=\"success\">Success</td>\n",
    "                    {% endif %}\n",
    "                </tr>\n",
    "                {% endfor %}\n",
    "            </table>\n",
    "        </div>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    template = Template(html_template)\n",
    "    \n",
    "    # Calculate total statistics\n",
    "    total_rows_processed = sum(report['original_rows'] for _, report in summary_report['cleaning_reports'].items() if 'error' not in report)\n",
    "    total_rows_cleaned = sum(report['cleaned_rows'] for _, report in summary_report['cleaning_reports'].items() if 'error' not in report)\n",
    "    total_null_values = sum(report['null_values'] for _, report in summary_report['cleaning_reports'].items() if 'error' not in report)\n",
    "    total_errors = sum(report['errors_found'] for _, report in summary_report['cleaning_reports'].items() if 'error' not in report)\n",
    "    \n",
    "    # Add totals to summary report\n",
    "    summary_report['total_rows_processed'] = total_rows_processed\n",
    "    summary_report['total_rows_cleaned'] = total_rows_cleaned\n",
    "    summary_report['total_null_values'] = total_null_values\n",
    "    summary_report['total_errors'] = total_errors\n",
    "    \n",
    "    # Generate HTML\n",
    "    html_content = template.render(summary=summary_report)\n",
    "    \n",
    "    # Save HTML report\n",
    "    report_path = os.path.join(output_folder, 'cleaning_report.html')\n",
    "    with open(report_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(html_content)\n",
    "    \n",
    "    return report_path\n",
    "\n",
    "def clean_csv_file(file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Clean a single CSV file and save the cleaned version with enhanced error tracking\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the CSV file\n",
    "        df = pd.read_csv(file_path)\n",
    "        original_columns = df.columns.tolist()\n",
    "        \n",
    "        # Store original row count\n",
    "        original_rows = len(df)\n",
    "        \n",
    "        # Count initial null values\n",
    "        initial_null_count = df.isnull().sum().sum()\n",
    "        \n",
    "        # Track errors found\n",
    "        errors_found = 0\n",
    "        \n",
    "        # Basic cleaning operations\n",
    "        \n",
    "        # 1. Remove duplicates\n",
    "        duplicates_removed = len(df) - len(df.drop_duplicates())\n",
    "        errors_found += duplicates_removed\n",
    "        df = df.drop_duplicates()\n",
    "        \n",
    "        # 2. Strip whitespace from string columns\n",
    "        string_columns = df.select_dtypes(include=['object']).columns\n",
    "        whitespace_errors = 0\n",
    "        for col in string_columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                whitespace_errors += df[col].str.strip().ne(df[col]).sum()\n",
    "                df[col] = df[col].str.strip()\n",
    "        errors_found += whitespace_errors\n",
    "        \n",
    "        # 3. Standardize text case in string columns\n",
    "        case_errors = 0\n",
    "        for col in string_columns:\n",
    "            if df[col].dtype == 'object':\n",
    "                case_errors += df[col].str.title().ne(df[col]).sum()\n",
    "                df[col] = df[col].str.title()\n",
    "        errors_found += case_errors\n",
    "            \n",
    "        # 4. Handle missing values\n",
    "        df = df.replace(r'^\\s*$', np.nan, regex=True)\n",
    "        \n",
    "        # Count null values after cleaning\n",
    "        final_null_count = df.isnull().sum().sum()\n",
    "        \n",
    "        # For numeric columns, fill NaN with median\n",
    "        numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "        for col in numeric_columns:\n",
    "            df[col] = df[col].fillna(df[col].median())\n",
    "            \n",
    "        # For string columns, fill NaN with 'Unknown'\n",
    "        for col in string_columns:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "            \n",
    "        # 5. Remove rows where all values are NaN\n",
    "        all_null_rows = len(df[df.isnull().all(axis=1)])\n",
    "        errors_found += all_null_rows\n",
    "        df = df.dropna(how='all')\n",
    "        \n",
    "        # Create cleaning report\n",
    "        cleaning_report = {\n",
    "            'original_rows': original_rows,\n",
    "            'cleaned_rows': len(df),\n",
    "            'rows_removed': original_rows - len(df),\n",
    "            'null_values': initial_null_count,\n",
    "            'errors_found': errors_found,\n",
    "            'columns_cleaned': original_columns\n",
    "        }\n",
    "        \n",
    "        # Create output filename while preserving the original folder structure\n",
    "        rel_path = os.path.relpath(file_path, \"Data\")\n",
    "        output_path = os.path.join(output_folder, rel_path)\n",
    "        output_dir = os.path.dirname(output_path)\n",
    "        \n",
    "        # Create the necessary subdirectories in the output folder\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Create output filename\n",
    "        base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        cleaned_file_path = os.path.join(output_dir, f'{base_name}_cleaned_{timestamp}.csv')\n",
    "        \n",
    "        # Save cleaned file\n",
    "        df.to_csv(cleaned_file_path, index=False)\n",
    "        \n",
    "        return cleaned_file_path, cleaning_report\n",
    "    \n",
    "    except Exception as e:\n",
    "        return None, {'error': str(e)}\n",
    "\n",
    "def find_csv_files(folder_path):\n",
    "    \"\"\"\n",
    "    Recursively find all CSV files in the given folder and its subfolders\n",
    "    \"\"\"\n",
    "    csv_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.csv'):\n",
    "                csv_files.append(os.path.join(root, file))\n",
    "    return csv_files\n",
    "\n",
    "def clean_data_folder(data_folder=\"Data\", output_folder=\"Cleaned_Data\"):\n",
    "    \"\"\"\n",
    "    Clean all CSV files in the Data folder and its subfolders with enhanced reporting\n",
    "    \"\"\"\n",
    "    # Check if Data folder exists\n",
    "    if not os.path.exists(data_folder):\n",
    "        print(f\"Error: {data_folder} folder not found!\")\n",
    "        return None\n",
    "    \n",
    "    # Create output folder if it doesn't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files\n",
    "    csv_files = find_csv_files(data_folder)\n",
    "    \n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in {data_folder} or its subfolders\")\n",
    "        return None\n",
    "    \n",
    "    # Initialize summary report\n",
    "    summary_report = {\n",
    "        'total_files': 0,\n",
    "        'successful_cleanings': 0,\n",
    "        'failed_cleanings': 0,\n",
    "        'cleaning_reports': {},\n",
    "        'folders_processed': set(),\n",
    "        'unique_columns': set()\n",
    "    }\n",
    "    \n",
    "    # Process each CSV file\n",
    "    for file_path in csv_files:\n",
    "        rel_path = os.path.relpath(file_path, data_folder)\n",
    "        print(f\"Processing: {rel_path}\")\n",
    "        \n",
    "        # Add folder to processed folders list\n",
    "        folder_path = os.path.dirname(rel_path)\n",
    "        if folder_path:\n",
    "            summary_report['folders_processed'].add(folder_path)\n",
    "        \n",
    "        cleaned_path, report = clean_csv_file(file_path, output_folder)\n",
    "        \n",
    "        summary_report['total_files'] += 1\n",
    "        if cleaned_path:\n",
    "            summary_report['successful_cleanings'] += 1\n",
    "            summary_report['cleaning_reports'][rel_path] = report\n",
    "            # Add columns to unique columns set\n",
    "            if 'columns_cleaned' in report:\n",
    "                summary_report['unique_columns'].update(report['columns_cleaned'])\n",
    "            print(f\"Successfully cleaned: {rel_path}\")\n",
    "        else:\n",
    "            summary_report['failed_cleanings'] += 1\n",
    "            summary_report['cleaning_reports'][rel_path] = report\n",
    "            print(f\"Failed to clean: {rel_path}\")\n",
    "    \n",
    "    # Convert sets to sorted lists for JSON serialization\n",
    "    summary_report['folders_processed'] = sorted(summary_report['folders_processed'])\n",
    "    summary_report['unique_columns'] = sorted(summary_report['unique_columns'])\n",
    "    \n",
    "    # Generate HTML report\n",
    "    report_path = generate_html_report(summary_report, output_folder)\n",
    "    print(f\"\\nHTML report generated at: {report_path}\")\n",
    "    \n",
    "    # Open the report in the default web browser\n",
    "    webbrowser.open('file://' + os.path.abspath(report_path))\n",
    "    \n",
    "    return summary_report\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Run the cleaning process\n",
    "    summary = clean_data_folder()\n",
    "    \n",
    "    if summary:\n",
    "        print(\"\\nCleaning process completed. Check the HTML report for detailed information.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
